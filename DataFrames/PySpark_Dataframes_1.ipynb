{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Contents\n",
    "\n",
    "- PySpark DataFrame\n",
    "- Reading the Dataset\n",
    "- Checking the Data-types of columns\n",
    "- Selecting columns and indexing\n",
    "- Describing a dataset\n",
    "- Adding Columns\n",
    "- Dropping Columns\n",
    "- Renaming Columns\n",
    "\n",
    "### All the operations seen in this notebook are not inPlace operations, Meaning, we need to assign all the operation to a dataframe in order to see the changes in effect.\n",
    "\n",
    "### If you will not assign the operations to a dataframe, it will show the results, but for that operation only, and the results of that operation won't be visible anywhere else."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Spark Session"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-25T07:49:21.709777400Z",
     "start_time": "2023-12-25T07:49:21.352732Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T07:49:34.991448100Z",
     "start_time": "2023-12-25T07:49:34.980907500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T07:50:49.169665900Z",
     "start_time": "2023-12-25T07:50:42.829225100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x1d9ab296f50>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-V83NRHM:4041\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>DataFrame</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T07:50:57.837340700Z",
     "start_time": "2023-12-25T07:50:56.471111Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_pyspark = spark.read.option('header','true').csv('test1.csv', inferSchema=True)\n",
    "\n",
    "# if we dont use inferschema, the above line will consider each column as string."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:37.670258900Z",
     "start_time": "2023-12-25T08:23:37.473541800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+\n",
      "|    Name|Age|Experience|   Location|\n",
      "+--------+---+----------+-----------+\n",
      "|  Priyam| 23|         2|  Bangalore|\n",
      "|  Kartik| 23|         2|      Noida|\n",
      "| Kshitiz| 22|         1|     Mumbai|\n",
      "|Akanksha| 24|         2|  Bangalore|\n",
      "|   Akhil| 23|         2|  Bangalore|\n",
      "|   Anmol| 22|         1|  Hyderabad|\n",
      "|   Sakib| 22|         1|     Mumbai|\n",
      "| Prateek| 23|         0|Robertsganj|\n",
      "+--------+---+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:37.851289Z",
     "start_time": "2023-12-25T08:23:37.757561700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Checking Schema\n",
    "df_pyspark.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:38.640484600Z",
     "start_time": "2023-12-25T08:23:38.624862600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alternate way of reading CSV files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Another Way of reading a CSV file\n",
    "\n",
    "df_pyspark = spark.read.csv('test1.csv', header = True, inferSchema = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:39.533357300Z",
     "start_time": "2023-12-25T08:23:39.373811Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## .show() is used to view a DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+\n",
      "|    Name|Age|Experience|   Location|\n",
      "+--------+---+----------+-----------+\n",
      "|  Priyam| 23|         2|  Bangalore|\n",
      "|  Kartik| 23|         2|      Noida|\n",
      "| Kshitiz| 22|         1|     Mumbai|\n",
      "|Akanksha| 24|         2|  Bangalore|\n",
      "|   Akhil| 23|         2|  Bangalore|\n",
      "|   Anmol| 22|         1|  Hyderabad|\n",
      "|   Sakib| 22|         1|     Mumbai|\n",
      "| Prateek| 23|         0|Robertsganj|\n",
      "+--------+---+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:40.626766900Z",
     "start_time": "2023-12-25T08:23:40.553579800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## .printSchema is used to Check Data type of each column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:41.264887100Z",
     "start_time": "2023-12-25T08:23:41.233640400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:41.785234Z",
     "start_time": "2023-12-25T08:23:41.769614600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['Name', 'Age', 'Experience', 'Location']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:42.116713900Z",
     "start_time": "2023-12-25T08:23:42.101090300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(Name='Priyam', Age=23, Experience=2, Location='Bangalore'),\n Row(Name='Kartik', Age=23, Experience=2, Location='Noida')]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:42.455110700Z",
     "start_time": "2023-12-25T08:23:42.381712800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    Name|\n",
      "+--------+\n",
      "|  Priyam|\n",
      "|  Kartik|\n",
      "| Kshitiz|\n",
      "|Akanksha|\n",
      "|   Akhil|\n",
      "|   Anmol|\n",
      "|   Sakib|\n",
      "| Prateek|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name']).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:43.252725300Z",
     "start_time": "2023-12-25T08:23:43.132811900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selecting Multiple Columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    Name|Experience|\n",
      "+--------+----------+\n",
      "|  Priyam|         2|\n",
      "|  Kartik|         2|\n",
      "| Kshitiz|         1|\n",
      "|Akanksha|         2|\n",
      "|   Akhil|         2|\n",
      "|   Anmol|         1|\n",
      "|   Sakib|         1|\n",
      "| Prateek|         0|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_pyspark.select(['Name', 'Experience']).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:43.726509400Z",
     "start_time": "2023-12-25T08:23:43.596954100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select(['Name']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:44.356852900Z",
     "start_time": "2023-12-25T08:23:44.292363400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking Data-types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Name', 'string'),\n ('Age', 'int'),\n ('Experience', 'int'),\n ('Location', 'string')]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_pyspark.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:45.009293200Z",
     "start_time": "2023-12-25T08:23:44.978051300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[summary: string, Name: string, Age: string, Experience: string, Location: string]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:45.463782200Z",
     "start_time": "2023-12-25T08:23:45.385705700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Describing a DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+------------------+-----------+\n",
      "|summary|    Name|               Age|        Experience|   Location|\n",
      "+-------+--------+------------------+------------------+-----------+\n",
      "|  count|       8|                 8|                 8|          8|\n",
      "|   mean|    NULL|             22.75|             1.375|       NULL|\n",
      "| stddev|    NULL|0.7071067811865472|0.7440238091428449|       NULL|\n",
      "|    min|Akanksha|                22|                 0|  Bangalore|\n",
      "|    max|   Sakib|                24|                 2|Robertsganj|\n",
      "+-------+--------+------------------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_pyspark.describe().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:45.968029200Z",
     "start_time": "2023-12-25T08:23:45.620155Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding Columns\n",
    "Addition is done based on an expression or transformation of existing columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('Age in Months', df_pyspark['Age']*12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:46.014898400Z",
     "start_time": "2023-12-25T08:23:45.968029200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+-------------+\n",
      "|    Name|Age|Experience|   Location|Age in Months|\n",
      "+--------+---+----------+-----------+-------------+\n",
      "|  Priyam| 23|         2|  Bangalore|          276|\n",
      "|  Kartik| 23|         2|      Noida|          276|\n",
      "| Kshitiz| 22|         1|     Mumbai|          264|\n",
      "|Akanksha| 24|         2|  Bangalore|          288|\n",
      "|   Akhil| 23|         2|  Bangalore|          276|\n",
      "|   Anmol| 22|         1|  Hyderabad|          264|\n",
      "|   Sakib| 22|         1|     Mumbai|          264|\n",
      "| Prateek| 23|         0|Robertsganj|          276|\n",
      "+--------+---+----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:23:49.850290800Z",
     "start_time": "2023-12-25T08:23:49.750490Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping a Column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\n",
    "df_pyspark = df_pyspark.drop('Age in Months')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:24:53.491349700Z",
     "start_time": "2023-12-25T08:24:53.459941100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------+\n",
      "|    Name|Age|Experience|   Location|\n",
      "+--------+---+----------+-----------+\n",
      "|  Priyam| 23|         2|  Bangalore|\n",
      "|  Kartik| 23|         2|      Noida|\n",
      "| Kshitiz| 22|         1|     Mumbai|\n",
      "|Akanksha| 24|         2|  Bangalore|\n",
      "|   Akhil| 23|         2|  Bangalore|\n",
      "|   Anmol| 22|         1|  Hyderabad|\n",
      "|   Sakib| 22|         1|     Mumbai|\n",
      "| Prateek| 23|         0|Robertsganj|\n",
      "+--------+---+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:24:54.841882300Z",
     "start_time": "2023-12-25T08:24:54.763248600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Renaming a Column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumnRenamed('Experience', 'Exp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:26:29.595888300Z",
     "start_time": "2023-12-25T08:26:29.595888300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+-----------+\n",
      "|    Name|Age|Exp|   Location|\n",
      "+--------+---+---+-----------+\n",
      "|  Priyam| 23|  2|  Bangalore|\n",
      "|  Kartik| 23|  2|      Noida|\n",
      "| Kshitiz| 22|  1|     Mumbai|\n",
      "|Akanksha| 24|  2|  Bangalore|\n",
      "|   Akhil| 23|  2|  Bangalore|\n",
      "|   Anmol| 22|  1|  Hyderabad|\n",
      "|   Sakib| 22|  1|     Mumbai|\n",
      "| Prateek| 23|  0|Robertsganj|\n",
      "+--------+---+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T08:26:34.781465300Z",
     "start_time": "2023-12-25T08:26:34.705931200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
